{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1ec4d5",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download\n",
    "\n",
    "# !pip install moviepy\n",
    "# !pip install pytube\n",
    "# os.chdir('so-vits-svc')\n",
    "# install requirements one-at-a-time to ignore exceptions\n",
    "# !cat requirements.txt | xargs -n 1 pip install --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install praat-parselmouth\n",
    "# !pip install ipywidgets\n",
    "# !pip install huggingface_hub\n",
    "# !pip install pip==23.0.1 # fix pip version for fairseq install\n",
    "# !pip install fairseq==0.12.2\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# existing_files = glob.glob('/content/**/*.*', recursive=True)\n",
    "# !pip install numpy==1.21\n",
    "# !pip install --upgrade protobuf=3.9.2\n",
    "# !pip uninstall -y tensorflow\n",
    "# !pip install tensorflow==2.11.0 \n",
    "\n",
    "#Optional\n",
    "\n",
    "# !pip uninstall torchaudio\n",
    "# !pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
    "\n",
    "# !pip install --upgrade numpy --user\n",
    "# !pip install --upgrade torch --user\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# !pip uninstall tensorflow --user\n",
    "# !pip install tensorflow --user\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9312ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "\n",
    "from pytube import YouTube\n",
    "import moviepy.editor as mp\n",
    "import glob\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from sys import platform\n",
    "import urllib.request\n",
    "import subprocess\n",
    "from time import sleep\n",
    "\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import gdown\n",
    "from os.path import exists\n",
    "\n",
    "import huggingface_hub\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import logging\n",
    "import io\n",
    "from ipywidgets import widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import torch\n",
    "\n",
    "import soundfile\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76397fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'so-vits-fdc'...\n"
     ]
    }
   ],
   "source": [
    "#git clone\n",
    "!git clone https://github.com/fdcellat/so-vits-fdc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1dbd10",
   "metadata": {},
   "source": [
    "## Download Video from Youtube (MP4) and convert MP3 or Wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a633a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in Ariana Grande & The Weeknd & Selena Gomez -Moth to a Flame  AI Cover.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# YouTube video URL\n",
    "video_url = \"https://www.youtube.com/watch?v=QSZMrrR1u3U&ab_channel=FDCAICovers\"\n",
    "\n",
    "# Download the YouTube video\n",
    "yt = YouTube(video_url)\n",
    "stream = yt.streams.get_audio_only()\n",
    "stream.download()\n",
    "\n",
    "# Convert the video to mp3\n",
    "video_path = stream.default_filename\n",
    "\n",
    "clip = mp.AudioFileClip(video_path)\n",
    "#clip.write_audiofile('Going Home.wav')\n",
    "clip.write_audiofile(video_path[:-4] + \".wav\")\n",
    "\n",
    "# Remove the original video file\n",
    "clip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68fe0b",
   "metadata": {},
   "source": [
    "## OR just use Mp4 to Mp3 or wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29243267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "\n",
    "# clip = AudioFileClip(filepath)\n",
    "# clip.write_audiofile(filepath)\n",
    "# clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42609f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Check GPU\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd42b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "# os.chdir(r\"C:\\\\Users\\\\User\\\\content\\\\so-vits-svc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95368756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"megatools\" not found. Downloading...\n",
      "Done!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "#@title Setup 2 (just run this once)\n",
    "os.chdir(r'C:\\\\Users\\\\User\\\\cont\\\\so-vits-fdc') # force working-directory to so-vits-svc - this line is just for safety and is probably not required\n",
    "\n",
    "# taken from https://github.com/CookiePPP/cookietts/blob/master/CookieTTS/utils/dataset/extract_unknown.py\n",
    "def extract(path):\n",
    "    if path.endswith(\".zip\"):\n",
    "        with ZipFile(path, 'r') as zipObj:\n",
    "           zipObj.extractall(os.path.split(path)[0])\n",
    "    elif path.endswith(\".tar.bz2\"):\n",
    "        tar = tarfile.open(path, \"r:bz2\")\n",
    "        tar.extractall(os.path.split(path)[0])\n",
    "        tar.close()\n",
    "    elif path.endswith(\".tar.gz\"):\n",
    "        tar = tarfile.open(path, \"r:gz\")\n",
    "        tar.extractall(os.path.split(path)[0])\n",
    "        tar.close()\n",
    "    elif path.endswith(\".tar\"):\n",
    "        tar = tarfile.open(path, \"r:\")\n",
    "        tar.extractall(os.path.split(path)[0])\n",
    "        tar.close()\n",
    "    elif path.endswith(\".7z\"):\n",
    "        import py7zr\n",
    "        archive = py7zr.SevenZipFile(path, mode='r')\n",
    "        archive.extractall(path=os.path.split(path)[0])\n",
    "        archive.close()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{path} extension not implemented.\")\n",
    "\n",
    "# taken from https://github.com/CookiePPP/cookietts/tree/master/CookieTTS/_0_download/scripts\n",
    "\n",
    "# megatools download urls\n",
    "win64_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-win64.zip\"\n",
    "win32_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-win32.zip\"\n",
    "linux_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-linux-x86_64.tar.gz\"\n",
    "# download megatools\n",
    "\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "        dl_url = linux_url\n",
    "elif platform == \"darwin\":\n",
    "    raise NotImplementedError('MacOS not supported.')\n",
    "elif platform == \"win32\":\n",
    "        dl_url = win64_url\n",
    "else:\n",
    "    raise NotImplementedError ('Unknown Operating System.')\n",
    "\n",
    "dlname = dl_url.split(\"/\")[-1]\n",
    "if dlname.endswith(\".zip\"):\n",
    "    binary_folder = dlname[:-4] # remove .zip\n",
    "elif dlname.endswith(\".tar.gz\"):\n",
    "    binary_folder = dlname[:-7] # remove .tar.gz\n",
    "else:\n",
    "    raise NameError('downloaded megatools has unknown archive file extension!')\n",
    "\n",
    "if not os.path.exists(binary_folder):\n",
    "    print('\"megatools\" not found. Downloading...')\n",
    "    if not os.path.exists(dlname):\n",
    "        urllib.request.urlretrieve(dl_url, dlname)\n",
    "    assert os.path.exists(dlname), 'failed to download.'\n",
    "    extract(dlname)\n",
    "    sleep(0.10)\n",
    "    os.unlink(dlname)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "binary_folder = os.path.abspath(binary_folder)\n",
    "\n",
    "def megadown(download_link, filename='.', verbose=False):\n",
    "    \"\"\"Use megatools binary executable to download files and folders from MEGA.nz .\"\"\"\n",
    "    filename = ' --path \"'+os.path.abspath(filename)+'\"' if filename else \"\"\n",
    "    wd_old = os.getcwd()\n",
    "    os.chdir(binary_folder)\n",
    "    try:\n",
    "        if platform == \"linux\" or platform == \"linux2\":\n",
    "            subprocess.call(f'./megatools dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}', shell=True)\n",
    "        elif platform == \"win32\":\n",
    "            subprocess.call(f'megatools.exe dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}', shell=True)\n",
    "    except:\n",
    "        os.chdir(wd_old) # don't let user stop download without going back to correct directory first\n",
    "        raise\n",
    "    os.chdir(wd_old)\n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "def request_url_with_progress_bar(url, filename):\n",
    "    class DownloadProgressBar(tqdm):\n",
    "        def update_to(self, b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                self.total = tsize\n",
    "            self.update(b * bsize - self.n)\n",
    "    \n",
    "    def download_url(url, filename):\n",
    "        with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                                 miniters=1, desc=url.split('/')[-1]) as t:\n",
    "            filename, headers = urllib.request.urlretrieve(url, filename=filename, reporthook=t.update_to)\n",
    "            print(\"Downloaded to \"+filename)\n",
    "    download_url(url, filename)\n",
    "\n",
    "\n",
    "def download(urls, dataset='', filenames=None, force_dl=False, username='', password='', auth_needed=False):\n",
    "    assert filenames is None or len(urls) == len(filenames), f\"number of urls does not match filenames. Expected {len(filenames)} urls, containing the files listed below.\\n{filenames}\"\n",
    "    assert not auth_needed or (len(username) and len(password)), f\"username and password needed for {dataset} Dataset\"\n",
    "    if filenames is None:\n",
    "        filenames = [None,]*len(urls)\n",
    "    for i, (url, filename) in enumerate(zip(urls, filenames)):\n",
    "        print(f\"Downloading File from {url}\")\n",
    "        #if filename is None:\n",
    "        #    filename = url.split(\"/\")[-1]\n",
    "        if filename and (not force_dl) and exists(filename):\n",
    "            print(f\"{filename} Already Exists, Skipping.\")\n",
    "            continue\n",
    "        if 'drive.google.com' in url:\n",
    "            assert 'https://drive.google.com/uc?id=' in url, 'Google Drive links should follow the format \"https://drive.google.com/uc?id=1eQAnaoDBGQZldPVk-nzgYzRbcPSmnpv6\".\\nWhere id=XXXXXXXXXXXXXXXXX is the Google Drive Share ID.'\n",
    "            gdown.download(url, filename, quiet=False)\n",
    "        elif 'mega.nz' in url:\n",
    "            megadown(url, filename)\n",
    "        else:\n",
    "            #urllib.request.urlretrieve(url, filename=filename) # no progress bar\n",
    "            request_url_with_progress_bar(url, filename) # with progress bar\n",
    "\n",
    "\n",
    "class HFModels:\n",
    "    def __init__(self, repo = \"therealvul/so-vits-svc-4.0\", \n",
    "            model_dir = \"hf_vul_models\"):\n",
    "        self.model_repo = huggingface_hub.Repository(local_dir=model_dir,\n",
    "            clone_from=repo, skip_lfs_files=True)\n",
    "        self.repo = repo\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        self.model_folders = os.listdir(model_dir)\n",
    "        self.model_folders.remove('.git')\n",
    "        self.model_folders.remove('.gitattributes')\n",
    "\n",
    "    def list_models(self):\n",
    "        return self.model_folders\n",
    "\n",
    "    # Downloads model;\n",
    "    # copies config to target_dir and moves model to target_dir\n",
    "    def download_model(self, model_name, target_dir):\n",
    "        if not model_name in self.model_folders:\n",
    "            raise Exception(model_name + \" not found\")\n",
    "        model_dir = self.model_dir\n",
    "        charpath = os.path.join(model_dir,model_name)\n",
    "\n",
    "        gen_pt = next(x for x in os.listdir(charpath) if x.startswith(\"G_\"))\n",
    "        cfg = next(x for x in os.listdir(charpath) if x.endswith(\"json\"))\n",
    "        try:\n",
    "          clust = next(x for x in os.listdir(charpath) if x.endswith(\"pt\"))\n",
    "        except StopIteration as e:\n",
    "          print(\"Note - no cluster model for \"+model_name)\n",
    "          clust = None\n",
    "\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "        gen_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
    "            filename = model_name + \"/\" + gen_pt) # this is a symlink\n",
    "        \n",
    "        if clust is not None:\n",
    "          clust_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
    "              filename = model_name + \"/\" + clust) # this is a symlink\n",
    "          shutil.move(os.path.realpath(clust_dir), os.path.join(target_dir, clust))\n",
    "          clust_out = os.path.join(target_dir, clust)\n",
    "        else:\n",
    "          clust_out = None\n",
    "\n",
    "        shutil.copy(os.path.join(charpath,cfg),os.path.join(target_dir, cfg))\n",
    "        shutil.move(os.path.realpath(gen_dir), os.path.join(target_dir, gen_pt))\n",
    "\n",
    "        return {\"config_path\": os.path.join(target_dir,cfg),\n",
    "            \"generator_path\": os.path.join(target_dir,gen_pt),\n",
    "            \"cluster_path\": clust_out}\n",
    "\n",
    "# Example usage\n",
    "# vul_models = HFModels()\n",
    "# print(vul_models.list_models())\n",
    "# print(\"Applejack (singing)\" in vul_models.list_models())\n",
    "# vul_models.download_model(\"Applejack (singing)\",\"models/Applejack (singing)\")\n",
    "\n",
    "    print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2bc0615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading File from https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/checkpoint_best_legacy_500.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint_best_legacy_500.pt: 1.33GB [01:54, 11.6MB/s]                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to hubert/checkpoint_best_legacy_500.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Download ContentVec (just run this once)\n",
    "os.chdir(r'C:\\\\Users\\\\User\\\\cont\\\\so-vits-fdc') # force working-directory to so-vits-svc - this line is just for safety and is probably not required\n",
    "download([\"https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/checkpoint_best_legacy_500.pt\"], filenames=[\"hubert/checkpoint_best_legacy_500.pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffee45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading File from https://huggingface.co/QuickWick/Music-AI-Voices/resolve/main/21%20Savage%20100k/21%20Savage%20100k.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21%20Savage%20100k.zip: 1.01GB [01:27, 11.5MB/s]                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to C:\\Users\\User\\cont\\so-vits-fdc\\21%20Savage%20100k.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@markdown Supported URL types: \n",
    "#@markdown * Google Drive zip\n",
    "#@markdown * MEGA zip\n",
    "#@markdown * Direct zip (+HuggingFace /resolve/ link)\n",
    "\n",
    "#@markdown Example URLs:\n",
    "#@markdown * Kanye: https://mega.nz/file/Dr40kCQI#G3bEWPvUvTa9SBJKQt7rETgcFds4ssnJF0nGN9aAXTk\n",
    "#@markdown * Kendrick: https://mega.nz/file/WmBzgSZa#UD-SFhHBv3aw0obTHW2lGc5yeaMnK8qtKU3OjDKMVKk\n",
    "#@markdown * Carti (v3): https://mega.nz/file/jnwzEJ4K#erlpUaNQ3VyQIIVaQDYge3Kv4pZtyNfQBWA6hUy6uu8\n",
    "#@markdown * Drake: https://mega.nz/file/Sm53wAwI#4PmIrSWDrEP1-pnZb5MJpTcfoHy3OBhBOhn2FVxfyb8\n",
    "#@markdown * Juice Wrld: https://mega.nz/file/5w9kGSJA#MQEQi7lBBBJMBa_rQ5mfGtDXnv96-XhhsNx-xc81ta8\n",
    "#@markdown * Travis: https://mega.nz/file/q652kCZb#VS9IE0Vr3A3PbynDvmkfantFmz_Iik9i3M9DMWeShoE\n",
    "#@markdown * Tyler: https://mega.nz/file/rz5SBBIK#KAhHX8tR-f5yf_aR4dRwF-oE90LpliA4E8v1YFC7ONQ\n",
    "#@markdown * Justin Bieber: https://huggingface.co/QuickWick/Music-AI-Voices/blob/main/Justin%20Bieber%2067k/justinbieber.zip\n",
    "#@markdown * The Weeknd: https://mega.nz/file/zQE2kBgJ#30r0jjqmOmtRJt_gG7RJa1yStwbbBbofCfYGqPyBEOQ\n",
    "#@markdown * Ariana Grande: https://mega.nz/file/SNZkRJhT#-c0Bj0o1-PTlXHWKfnrVbOfw0OKQ5J1RBMhvk7kpi4o\n",
    "#@markdown * bruno mars =https://mega.nz/file/RlgXFbxD#qngpPYWSI1vnsh43tmrj3EHcHZ-E3eRA_wgkepTpZQ4\n",
    "#@markdown * harry styles= https://mega.nz/file/RlgXFbxD#qngpPYWSI1vnsh43tmrj3EHcHZ-E3eRA_wgkepTpZQ4\n",
    "#@markdown * doja cat =  https://mega.nz/file/k5oU2JJI#6eNZ9sAIbr-GPq1SctEAq5mmdeOHAZPs0WKHXKxb2Fc\n",
    "\n",
    "\n",
    "\n",
    "model_url = \"https://huggingface.co/QuickWick/Music-AI-Voices/blob/main/21%20Savage%20100k/21%20Savage%20100k.zip\" #@param {\"type\": \"string\"}\n",
    "if \"huggingface.co\" in model_url.lower():\n",
    "  download([re.sub(r\"/blob/\",\"/resolve/\",model_url)], \n",
    "           filenames=[os.path.join(os.getcwd(),model_url.split(\"/\")[-1])])\n",
    "else:\n",
    "  download([model_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b6a19f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting zip C:\\\\Users\\\\User\\\\cont\\so-vits-fdc\\21%20Savage%20100k.zip\n"
     ]
    }
   ],
   "source": [
    "#@title Extract .zip Downloads - Step o.2\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model_zip_paths = glob.glob(r'C:\\\\Users\\\\User\\\\cont\\\\**\\\\*.zip', recursive=True)\n",
    "\n",
    "for model_zip_path in model_zip_paths:\n",
    "    print(\"extracting zip\",model_zip_path)\n",
    "    output_dir = os.path.join(r'C:\\\\Users\\\\User\\\\cont\\\\so-vits-fdc\\\\models',os.path.basename(os.path.splitext(model_zip_path)[0]).replace(\" \",\"_\"))\n",
    "    os.mkdir(output_dir)\n",
    "    input_base = os.path.dirname(model_zip_path)\n",
    "    # do the extract\n",
    "    extract(model_zip_path)\n",
    "    ckpts = glob.glob(os.path.join(input_base,'**/*.pth'),recursive=True)\n",
    "    jsons = glob.glob(os.path.join(input_base,'**/config.json'),recursive=True)\n",
    "#     for ckpt in ckpts:\n",
    "#       shutil.move(ckpt,os.path.join(output_dir,os.path.basename(ckpt)))\n",
    "#     for json in jsons:\n",
    "#       shutil.move(json,os.path.join(output_dir,os.path.basename(json)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8970c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import infer_tool\n",
    "from inference import slicer\n",
    "from inference.infer_tool import Svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa5b5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 21%20Savage%20100k, no G_*.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8164836ca44bcfb7900e3e40c19ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371bb17be1cb4719ad6c9295729a4acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Transpose')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9ade852ca14c489567a1be65acf9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0, description='Clustering Ratio')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f8c32feb654cb0a48ce796024caeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.4, description='Noise Scale')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d1421b0e564e6aaf90cd112126e6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Auto pitch f0 (do not use for singing)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee647b5304945388719b8b7cfc634a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Convert', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edeb6fb848d4e4bb5fb8566a5a8e638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Delete all audio files', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MODELS_DIR = \"models\"\n",
    "\n",
    "def get_speakers():\n",
    "  speakers = []\n",
    "  for _,dirs,_ in os.walk(MODELS_DIR):\n",
    "    for folder in dirs:\n",
    "      cur_speaker = {}\n",
    "      # Look for G_****.pth\n",
    "      g = glob.glob(os.path.join(MODELS_DIR,folder,'G_*.pth'))\n",
    "      if not len(g):\n",
    "        print(\"Skipping \"+folder+\", no G_*.pth\")\n",
    "        continue\n",
    "      cur_speaker[\"model_path\"] = g[0]\n",
    "      cur_speaker[\"model_folder\"] = folder\n",
    "\n",
    "      # Look for *.pt (clustering model)\n",
    "      clst = glob.glob(os.path.join(MODELS_DIR,folder,'*.pt'))\n",
    "      if not len(clst):\n",
    "        print(\"Note: No clustering model found for \"+folder)\n",
    "        cur_speaker[\"cluster_path\"] = \"\"\n",
    "      else:\n",
    "        cur_speaker[\"cluster_path\"] = clst[0]\n",
    "\n",
    "      # Look for config.json\n",
    "      cfg = glob.glob(os.path.join(MODELS_DIR,folder,'*.json'))\n",
    "      if not len(cfg):\n",
    "        print(\"Skipping \"+folder+\", no config json\")\n",
    "        continue\n",
    "      cur_speaker[\"cfg_path\"] = cfg[0]\n",
    "      with open(cur_speaker[\"cfg_path\"]) as f:\n",
    "        try:\n",
    "          cfg_json = json.loads(f.read())\n",
    "        except Exception as e:\n",
    "          print(\"Malformed config json in \"+folder)\n",
    "        for name, i in cfg_json[\"spk\"].items():\n",
    "          cur_speaker[\"name\"] = name\n",
    "          cur_speaker[\"id\"] = i\n",
    "          if not name.startswith('.'):\n",
    "            speakers.append(copy.copy(cur_speaker))\n",
    "\n",
    "    return sorted(speakers, key=lambda x:x[\"name\"].lower())\n",
    "\n",
    "logging.getLogger('numba').setLevel(logging.WARNING)\n",
    "chunks_dict = infer_tool.read_temp(\"inference/chunks_temp.json\")\n",
    "existing_files = []\n",
    "slice_db = -40\n",
    "wav_format = 'wav'\n",
    "\n",
    "class InferenceGui():\n",
    "  def __init__(self):\n",
    "    self.speakers = get_speakers()\n",
    "    self.speaker_list = [x[\"name\"] for x in self.speakers]\n",
    "    self.speaker_box = widgets.Dropdown(\n",
    "        options = self.speaker_list\n",
    "    )\n",
    "    display(self.speaker_box)\n",
    "\n",
    "    def convert_cb(btn):\n",
    "      self.convert()\n",
    "    def clean_cb(btn):\n",
    "      self.clean()\n",
    "\n",
    "    self.convert_btn = widgets.Button(description=\"Convert\")\n",
    "    self.convert_btn.on_click(convert_cb)\n",
    "    self.clean_btn = widgets.Button(description=\"Delete all audio files\")\n",
    "    self.clean_btn.on_click(clean_cb)\n",
    "\n",
    "    self.trans_tx = widgets.IntText(value=0, description='Transpose')\n",
    "    self.cluster_ratio_tx = widgets.FloatText(value=0.0, \n",
    "      description='Clustering Ratio')\n",
    "    self.noise_scale_tx = widgets.FloatText(value=0.4, \n",
    "      description='Noise Scale')\n",
    "    self.auto_pitch_ck = widgets.Checkbox(value=False, description=\n",
    "      'Auto pitch f0 (do not use for singing)')\n",
    "\n",
    "    display(self.trans_tx)\n",
    "    display(self.cluster_ratio_tx)\n",
    "    display(self.noise_scale_tx)\n",
    "    display(self.auto_pitch_ck)\n",
    "    display(self.convert_btn)\n",
    "    display(self.clean_btn)\n",
    "\n",
    "  def convert(self):\n",
    "    trans = int(self.trans_tx.value)\n",
    "    speaker = next(x for x in self.speakers if x[\"name\"] == \n",
    "          self.speaker_box.value)\n",
    "    spkpth2 = os.path.join(os.getcwd(),speaker[\"model_path\"])\n",
    "    print(spkpth2)\n",
    "    print(os.path.exists(spkpth2))\n",
    "\n",
    "    svc_model = Svc(speaker[\"model_path\"], speaker[\"cfg_path\"], \n",
    "      cluster_model_path=speaker[\"cluster_path\"])\n",
    "    \n",
    "    input_filepaths = [f for f in glob.glob(r'C:\\\\Users\\\\User\\\\cont\\\\**\\\\*.*', recursive=True)\n",
    "     if f not in existing_files and \n",
    "     any(f.endswith(ex) for ex in ['.wav','.flac','.mp3','.ogg','.opus'])]\n",
    "    for name in input_filepaths:\n",
    "      print(\"Converting \"+os.path.split(name)[-1])\n",
    "      infer_tool.format_wav(name)\n",
    "\n",
    "      wav_path = str(Path(name).with_suffix('.wav'))\n",
    "      wav_name = Path(name).stem\n",
    "      chunks = slicer.cut(wav_path, db_thresh=slice_db)\n",
    "      audio_data, audio_sr = slicer.chunks2audio(wav_path, chunks)\n",
    "\n",
    "      audio = []\n",
    "      for (slice_tag, data) in audio_data:\n",
    "          print(f'#=====segment start, '\n",
    "              f'{round(len(data)/audio_sr, 3)}s======')\n",
    "          \n",
    "          length = int(np.ceil(len(data) / audio_sr *\n",
    "              svc_model.target_sample))\n",
    "          \n",
    "          if slice_tag:\n",
    "              print('jump empty segment')\n",
    "              _audio = np.zeros(length)\n",
    "          else:\n",
    "              # Padding \"fix\" for noise\n",
    "              pad_len = int(audio_sr * 0.5)\n",
    "              data = np.concatenate([np.zeros([pad_len]),\n",
    "                  data, np.zeros([pad_len])])\n",
    "              raw_path = io.BytesIO()\n",
    "              soundfile.write(raw_path, data, audio_sr, format=\"wav\")\n",
    "              raw_path.seek(0)\n",
    "              _cluster_ratio = 0.0\n",
    "              if speaker[\"cluster_path\"] != \"\":\n",
    "                _cluster_ratio = float(self.cluster_ratio_tx.value)\n",
    "              out_audio, out_sr = svc_model.infer(\n",
    "                  speaker[\"name\"], trans, raw_path,\n",
    "                  cluster_infer_ratio = _cluster_ratio,\n",
    "                  auto_predict_f0 = bool(self.auto_pitch_ck.value),\n",
    "                  noice_scale = float(self.noise_scale_tx.value))\n",
    "              _audio = out_audio.cpu().numpy()\n",
    "              pad_len = int(svc_model.target_sample * 0.5)\n",
    "              _audio = _audio[pad_len:-pad_len]\n",
    "          audio.extend(list(infer_tool.pad_array(_audio, length)))\n",
    "          \n",
    "      res_path = os.path.join(r'C:\\\\Users\\\\User\\\\content\\\\',\n",
    "          f'{wav_name}_{trans}_key_'\n",
    "          f'{speaker[\"name\"]}.{wav_format}')\n",
    "      soundfile.write(res_path, audio, svc_model.target_sample,\n",
    "          format=wav_format)\n",
    "      display(Audio(res_path, autoplay=True)) # display audio file\n",
    "    pass\n",
    "\n",
    "  def clean(self):\n",
    "     input_filepaths = [f for f in glob.glob(r'C:\\\\Users\\\\User\\\\cont\\\\**\\\\*.*', recursive=True)\n",
    "     if f not in existing_files and \n",
    "     any(f.endswith(ex) for ex in ['.wav','.flac','.mp3','.ogg','.opus'])]\n",
    "     for f in input_filepaths:\n",
    "       os.remove(f)\n",
    "\n",
    "inference_gui = InferenceGui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7fa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a6bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
